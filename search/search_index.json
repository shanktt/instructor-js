{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Instructor-js","text":"<p>Structured extraction in Typescript, powered by llms, designed for simplicity, transparency, and control.</p> <p> </p> <p>Dive into the world of Typescript-based structured extraction, by OpenAI's function calling API and Zod, typeScript-first schema validation with static type inference. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you're a seasoned developer or just starting out, you'll find Instructor's approach intuitive and steerable.</p> <p>Support in other languages</p> <p>Check out ports to other languages below:</p> <ul> <li>Python</li> <li>Elixir</li> </ul> <p>If you want to port Instructor to another language, please reach out to us on Twitter we'd love to help you get started!</p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst UserSchema = z.object({\n  age: z.number(),\n  name: z.string()\n})\n\ntype User = z.infer&lt;typeof UserSchema&gt;\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nconst user: User = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Jason Liu is 30 years old\" }],\n  model: \"gpt-3.5-turbo\",\n  response_model: { schema: UserSchema }\n})\n\nconsole.log(user)\n// { age: 30, name: \"Jason Liu\" }\n</code></pre>"},{"location":"#why-use-instructor","title":"Why use Instructor?","text":"<p>The question of using Instructor is fundamentally a question of why to use Pydantic.</p> <ol> <li> <p>Powered by OpenAI \u2014 Instructor is powered by OpenAI's function calling API. This means you can use the same API for both prompting and extraction.</p> </li> <li> <p>Customizable \u2014 Zod is highly customizable. You can define your own validators, custom error messages, and more.</p> </li> <li> <p>Ecosystem Zod is the most widely used data validation library for Typescript.</p> </li> <li> <p>Battle Tested \u2014 Zod is downloaded over 24M times per month, and supported by a large community of contributors.</p> </li> </ol>"},{"location":"#more-examples","title":"More Examples","text":"<p>If you'd like to see more check out our cookbook.</p> <p>Installing Instructor is a breeze. </p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you want to help out, checkout some of the issues marked as <code>good-first-issue</code> or <code>help-wanted</code>. Found here. They could be anything from code improvements, a guest blog post, or a new cook book.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT License.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We would love for you to contribute to <code>Instructor-js</code>.</p>"},{"location":"contributing/#migrating-docs-from-python","title":"Migrating Docs from Python","text":"<p>Theres a bunch of examples in the python version, including documentation here python docs</p> <p>If you want to contribute, please check out issues</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>If you find a bug, please file an issue on our issue tracker on GitHub.</p> <p>To help us reproduce the bug, please provide a minimal reproducible example, including a code snippet and the full error message.</p> <ol> <li>The <code>response_model</code> you are using.</li> <li>The <code>messages</code> you are using.</li> <li>The <code>model</code> you are using.</li> </ol>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>We welcome pull requests! There is plenty to do, and we are happy to discuss any contributions you would like to make.</p> <p>If it is not a small change, please start by filing an issue first.</p> <p>If you need ideas, you can check out the help wanted or good first issue labels.</p>"},{"location":"contributing/#contributors","title":"Contributors","text":""},{"location":"contributing/#additional-resources","title":"Additional Resources","text":"<p>To enhance your understanding of the documentation, here are some useful references:</p> <ul> <li> <p>mkdocs serve: The <code>mkdocs serve</code> command is used to preview your documentation locally during the development phase. When you run this command in your terminal, MkDocs starts a development server, allowing you to view and interact with your documentation in a web browser. This is helpful for checking how your changes look before publishing the documentation. Learn more in the mkdocs serve documentation.</p> </li> <li> <p>hl_lines in Code Blocks: The <code>hl_lines</code> feature in code blocks allows you to highlight specific lines within the code block. This is useful for drawing attention to particular lines of code when explaining examples or providing instructions. You can specify the lines to highlight using the <code>hl_lines</code> option in your code block configuration. For more details and examples, you can refer to the hl_lines documentation.</p> </li> <li> <p>Admonitions: Admonitions are a way to visually emphasize or call attention to certain pieces of information in your documentation. They come in various styles, such as notes, warnings, tips, etc. Admonitions provide a structured and consistent way to present important content. For usage examples and details on incorporating admonitions into your documentation, you can refer to the admonitions documentation.</p> </li> </ul> <p>For more details about the documentation structure and features, refer to the MkDocs Material documentation.</p> <p>Thank you for your contributions, and happy coding!</p>"},{"location":"help/","title":"Help with Instructor","text":"<p>Page under construction</p> <p>This page is under construction. Please check back later. Consider contributing to this page by opening a PR! </p>"},{"location":"help/#getting-help-with-instructor","title":"Getting help with Instructor","text":"<p>If you need help getting started with Instructor or with advanced usage, the following sources may be useful.</p>"},{"location":"help/#material-discord-discord","title":":material-discord: Discord","text":"<p>The Discord is the best place to get help. You can ask questions, get help with debugging, and discuss Instructor with other users.</p>"},{"location":"help/#concepts","title":"Concepts","text":"<p>The concepts section explains the core concepts of Instructor and how to prompt with models.</p>"},{"location":"help/#cookbooks","title":"Cookbooks","text":"<p>The cookbooks are a great place to start. They contain a variety of examples that demonstrate how to use Instructor in different scenarios.</p>"},{"location":"help/#github-discussions","title":"GitHub Discussions","text":"<p>GitHub discussions are useful for asking questions, your question and the answer will help everyone.</p>"},{"location":"help/#github-issues","title":"GitHub Issues","text":"<p>GitHub issues are useful for reporting bugs or requesting new features.</p>"},{"location":"help/#twitter","title":"Twitter","text":"<p>You can also reach out to me on Twitter if you have any questions or ideas.</p>"},{"location":"installation/","title":"Installation","text":"<p>Installation is as simple as:</p> <p>Warning</p> <p>\"We haven't released instructor-js to npm yet. Please directly clone the repository and use\"</p> <pre><code>npm install instructor-js\n</code></pre> <p>Instructor-js has a few dependencies:</p> <ul> <li><code>openai</code>: OpenAI's  TypeScript / JavaScript library.</li> <li><code>zod</code>: TypeScript-first schema validation with static type inference.</li> </ul> <p>If you've got Typescript 5.3.3+ installed, you're good to go.</p>"},{"location":"why/","title":"Why use Instructor?","text":"<p>Page under construction</p> <p>This page is under construction. Please check back later. Consider contributing to this page by opening a PR! </p>"},{"location":"blog/","title":"Welcome to the Instructor Blog","text":"<p>If you wanted to check out the main blog check us out here where we have a bunch of posts about Instructor and OpenAI, and how to think about building with structured prompting. This blog will be more focused on the technical details of the javascript library.</p> <ul> <li>Support for Anyscale's Mistral</li> </ul>"},{"location":"blog/2024/01/01/patching/","title":"Structured Outputs with Anyscale and Zod","text":"<p>Open-source LLMS are gaining popularity, and the release of Anyscale's Mistral model has made it possible to obtain structured outputs using JSON schema at any scale. Instead of relying on a model's default output mode, you can utilize JSON schema to obtain structured outputs. This approach is a time-saving alternative to extensive prompt engineering.</p> <p>By the end of this blog post, you will learn how to effectively utilize instructor with Anyscale. But before we proceed, let's first explore the concept of patching.</p>","tags":["patching","open source"]},{"location":"blog/2024/01/01/patching/#understanding-modes","title":"Understanding Modes","text":"<p>Instructor's patch enhances a openai api it with the following features, you can learn more about them here, for anyscale they support <code>JSON_SCHEMA</code> and <code>FUNCTIONS</code> modes. and with instructor we'll be able to use the following features:</p> <ul> <li><code>response_model</code> in <code>create</code> calls that returns a pydantic model</li> <li><code>max_retries</code> in <code>create</code> calls that retries the call if it fails by using a backoff strategy</li> </ul>","tags":["patching","open source"]},{"location":"blog/2024/01/01/patching/#anyscale","title":"Anyscale","text":"<p>The good news is that Anyscale employs the same OpenAI client, and its models support some of these output modes too!</p> <p>Getting access</p> <p>If you want to try this out for yourself check out the Anyscale website. You can get started here.</p> <p>Let's explore one of the models available in Anyscale's extensive collection!</p> <p><pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst property = z.object({\n  name: z.string(),\n  value: z.string()\n}).describe(\"A property defined by a name and value\")\n\nconst UserSchema = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.array(property)\n})\n\nconst oai = new OpenAI({\n  baseURL: \"https://api.endpoints.anyscale.com/v1\",\n  apiKey: process.env.ANYSCALE_API_KEY ?? undefined,\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"JSON_SCHEMA\"\n})\n\nconst user = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: \"Harry Potter\" }],\n  model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n  response_model: { schema: UserSchema },\n  max_retries: 3\n})\n\nconsole.log(user)\n/**\n * {\n  age: 17,\n  name: \"Harry Potter\",\n  properties: [\n    {\n      name: \"House\",\n      value: \"Gryffindor\",\n    }, {\n      name: \"Wand\",\n      value: \"Holly and Phoenix feather\",\n    }\n  ],\n}\n */\n</code></pre> You can find more information about Anyscale's output mode support here.</p>","tags":["patching","open source"]},{"location":"concepts/modes/","title":"Modes","text":"<p>Instructor enhances client functionality with three new keywords for backwards compatibility. This allows use of the enhanced client as usual, with structured output benefits.</p> <ul> <li><code>response_model</code>: Defines the response type for <code>chat.completions.create</code>.</li> <li><code>max_retries</code>: Determines retry attempts for failed <code>chat.completions.create</code> validations.</li> <li><code>validation_context</code>: Provides extra context to the validation process.</li> </ul> <p>There are three methods for structured output:</p> <ol> <li>Function Calling: The primary method. Use this for stability and testing.</li> <li>Tool Calling: Useful in specific scenarios; lacks the reasking feature of OpenAI's tool calling API.</li> <li>JSON Mode: Offers closer adherence to JSON but with more potential validation errors. Suitable for specific non-function calling clients.</li> </ol>"},{"location":"concepts/modes/#function-calling","title":"Function Calling","text":"<pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst client = Instructor({\n    client: oai,\n    mode: \"FUNCTIONS\",\n})\n</code></pre>"},{"location":"concepts/modes/#tool-calling","title":"Tool Calling","text":"<pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst client = Instructor({\n    client: oai,\n    mode: \"TOOLS\",\n})\n</code></pre>"},{"location":"concepts/modes/#json-mode","title":"JSON Mode","text":"<pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst client = Instructor({\n    client: oai,\n    mode: \"JSON\",\n})\n</code></pre>"},{"location":"concepts/modes/#markdown-json-mode","title":"Markdown JSON Mode","text":"<p>Experimental</p> <p>This is not recommended, and may not be supported in the future, this is just left to support vision models.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst oai = new OpenAI({})\nconst client = Instructor({\n    client: oai,\n    mode: \"MD_JSON\",\n})\n</code></pre>"},{"location":"concepts/schema/","title":"Schema","text":"<p>Page under construction</p> <p>This page is under construction. Please check back later. Consider contributing to this page by opening a PR! </p>"},{"location":"concepts/streaming/","title":"Streaming","text":"<p>A common use case of structured extraction is defining a single schema class and then making another schema to create a list to do multiple extraction By enabling streaming, you can do multiple extractions in a single request, and then iterate over the results as they come in.</p> <p>Important: Changes in Response Behavior with Streaming Enabled</p> <p>Enabling streaming alters the nature of the response you receive:</p> <p>Response Type: When streaming is enabled, the response becomes an Async Generator. This generator produces incremental updates until the final result is achieved.</p> <p>Handling the Data: As the Async Generator yields results, you can iterate over these incremental updates. It's important to note that the data from each yield is a complete snapshot of the current extraction state and is immediately usable.</p> <p>Final Value: The last value yielded by the generator represents the completed extraction. This value should be used as the final result.</p> <p>Example: Extracting Conference Information The following TypeScript example demonstrates how to use an Async Generator for streaming responses. It includes a schema definition for extraction and iterates over a stream of data to incrementally update and display the extracted information.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\n\nconst textBlock = `\nIn our recent online meeting, participants from various backgrounds joined to discuss the upcoming tech conference. The names and contact details of the participants were as follows:\n\n- Name: John Doe, Email: johndoe@email.com, Twitter: @TechGuru44\n- Name: Jane Smith, Email: janesmith@email.com, Twitter: @DigitalDiva88\n- Name: Alex Johnson, Email: alexj@email.com, Twitter: @CodeMaster2023\n- Name: Emily Clark, Email: emilyc@email.com, Twitter: @InnovateQueen\n- Name: Ron Stewart, Email: ronstewart@email.com, Twitter: @RoboticsRon5\n- Name: Sarah Lee, Email: sarahlee@email.com, Twitter: @AI_Aficionado\n- Name: Mike Brown, Email: mikeb@email.com, Twitter: @FutureTechLeader\n- Name: Lisa Green, Email: lisag@email.com, Twitter: @CyberSavvy101\n- Name: David Wilson, Email: davidw@email.com, Twitter: @GadgetGeek77\n- Name: Daniel Kim, Email: danielk@email.com, Twitter: @DataDrivenDude\n\nDuring the meeting, we agreed on several key points. The conference will be held on March 15th, 2024, at the Grand Tech Arena located at 4521 Innovation Drive. Dr. Emily Johnson, a renowned AI researcher, will be our keynote speaker.\n\nThe budget for the event is set at $50,000, covering venue costs, speaker fees, and promotional activities. Each participant is expected to contribute an article to the conference blog by February 20th.\n\nA follow-up meeting is scheduled for January 25th at 3 PM GMT to finalize the agenda and confirm the list of speakers.\n`\n\n\nconst ExtractionValuesSchema = z.object({\n  users: z\n    .array(\n      z.object({\n        name: z.string(),\n        handle: z.string(),\n        twitter: z.string()\n      })\n    )\n    .min(5),\n  date: z.string(),\n  location: z.string(),\n  budget: z.number(),\n  deadline: z.string().min(1)\n})\n\ntype Extraction = Partial&lt;z.infer&lt;typeof ExtractionValuesSchema&gt;&gt;\n\nconst oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"TOOLS\"\n})\n\nconst extractionStream = await client.chat.completions.create({\n  messages: [{ role: \"user\", content: textBlock }],\n  model: \"gpt-4-1106-preview\",\n  response_model: { schema ExtractionValuesSchema },\n  max_retries: 3,\n  stream: true\n})\n\nlet extraction: Extraction = {}\n\nfor await (const result of extractionStream) {\n  try {\n    extraction = result\n    console.clear()\n    console.table(extraction)\n  } catch (e) {\n    console.log(e)\n    break\n  }\n}\n\nconsole.clear()\nconsole.log(\"completed extraction:\")\nconsole.table(extraction)\n</code></pre>"},{"location":"concepts/streaming/#understanding-openai-completion-requests-and-streaming-responses","title":"Understanding OpenAI Completion Requests and Streaming Responses","text":"<p>Server-Sent Events (SSE) and Async Generators</p> <p>OpenAI's completion requests return responses using Server-Sent Events (SSE), a protocol used to push real-time updates from a server to a client. In this context, the Async Generator in our TypeScript example closely mirrors the behavior of SSE. Each yield from the Async Generator corresponds to an update from the server, providing a continuous stream of data until the completion of the request.</p> <p>Transforming Async Generators to Readable Streams</p> <p>While the Async Generator is suitable for server-side processing of streaming data, there may be scenarios where you need to stream data to a client, such as a web browser. In such cases, you can transform the Async Generator into a ReadableStream, which is more suitable for client-side consumption.</p> <p>Here's how you can transform an Async Generator to a ReadableStream:</p> <pre><code>import { ReadableStream } from 'stream';\n\nfunction asyncGeneratorToReadableStream(generator) {\n  const encoder = new TextEncoder();\n\n  return new ReadableStream({\n    async start(controller) {\n      for await (const parsedData of generator) {\n        controller.enqueue(encoder.encode(JSON.stringify(parsedData)));\n      }\n      controller.close();\n    },\n    cancel() {\n      if (cancelGenerator) {\n        cancelGenerator(); \n      }\n    }\n  });\n}\n\n// Usage Example\nconst readableStream = asyncGeneratorToReadableStream(extractionStream);\n\n// This ReadableStream can now be returned in an API endpoint or used in a similar context\n</code></pre> <p>In this example:</p> <p>The asyncGeneratorToReadableStream function takes an Async Generator and an optional cancellation function.</p> <p>It creates a new ReadableStream that, upon starting, iterates over the Async Generator using a for await...of loop.</p> <p>Each piece of parsed data from the generator is encoded and enqueued into the stream. Once the generator completes, the stream is closed using controller.close().</p> <p>If the stream is canceled (e.g., client disconnects), an optional cancelGenerator function can be invoked to stop the generator.</p> <p>This approach allows for seamless integration of OpenAI's streaming completion responses into web applications and other scenarios where streaming data directly to a client is required.</p>"},{"location":"concepts/tips/","title":"General Guidelines for Zod Schema Engineering","text":"<p>When using Zod for schema definition and validation, adhere to principles ensuring clarity, modularity, and flexibility, similar to Pydantic.</p> <ul> <li>Modularity: Construct self-contained schemas for reuse.</li> <li>Self-Description: Describe fields using Zod's <code>.describe()</code> for clarity.</li> <li>Optionality: Utilize <code>z.union</code> with <code>z.undefined()</code> for optional fields.</li> <li>Standardization: Use <code>z.enum</code> for fields with a specific set of values, including a 'Other' option for ambiguity.</li> <li>Dynamic Data: Apply <code>z.record(z.string())</code> for arbitrary properties, with controlled key-value pairs.</li> <li>Entity Relationships: Define relationships through explicit identifiers and relationship fields.</li> <li>Contextual Logic: Add an optional 'chain of thought' field for context.</li> </ul>"},{"location":"concepts/tips/#modular-chain-of-thought","title":"Modular Chain of Thought","text":"<p>Leverage Zod's flexibility for modular 'chain of thought', enhancing data quality.</p> <pre><code>import { z } from 'zod';\n\nconst Role = z.object({\n  chainOfThought: z.string().describe(\"Sequential reasoning to determine the correct title\"),\n  title: z.string(),\n});\n\nconst UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  role: Role,\n});\n</code></pre>"},{"location":"concepts/tips/#utilizing-optional-attributes","title":"Utilizing Optional Attributes","text":"<p>For optional fields, use <code>z.union</code> with <code>z.undefined()</code>.</p> <pre><code>const UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  role: z.string().optional(),\n});\n</code></pre>"},{"location":"concepts/tips/#error-handling-within-schemas","title":"Error Handling Within Schemas","text":"<p>Create a wrapper schema for handling both successful and error states.</p> <pre><code>const MaybeUser = z.object({\n  result: UserDetail.optional(),\n  error: z.boolean(),\n  message: z.string().optional(),\n});\n\n// `MaybeUser` can now encapsulate both a result and an error state.\n</code></pre>"},{"location":"concepts/tips/#simplification-with-dynamic-patterns","title":"Simplification with Dynamic Patterns","text":"<p>Utilize Zod's dynamic schema creation for streamlining error handling.</p> <pre><code>const Maybe = (schema) =&gt; z.object({\n  result: schema.optional(),\n  error: z.boolean(),\n  message: z.string().optional(),\n});\n\nconst MaybeUser = Maybe(UserDetail);\n</code></pre>"},{"location":"concepts/tips/#tips-for-enumerations","title":"Tips for Enumerations","text":"<p>Implement <code>z.enum</code> for standardized fields, including an 'Other' option.</p> <pre><code>const Role = z.enum([\"PRINCIPAL\", \"TEACHER\", \"STUDENT\", \"OTHER\"]);\n\nconst UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  role: Role,\n});\n</code></pre>"},{"location":"concepts/tips/#reiterate-long-instructions","title":"Reiterate Long Instructions","text":"<p>For complex attributes, restate instructions in the field's description.</p> <pre><code>const Role = z.object({\n  instructions: z.string().describe(\"Repeat the rules for determining the title.\"),\n  title: z.string(),\n});\n</code></pre>"},{"location":"concepts/tips/#handling-arbitrary-properties","title":"Handling Arbitrary Properties","text":"<p>Use <code>z.record(z.string())</code> for undefined attributes.</p> <pre><code>const UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.record(z.string()).describe(\"Arbitrary key-value pairs\"),\n});\n</code></pre>"},{"location":"concepts/tips/#limiting-list-lengths","title":"Limiting List Lengths","text":"<p>Control list lengths through Zod's array validations.</p> <pre><code>const Property = z.object({\n  key: z.string(),\n  value: z.string(),\n});\n\nconst UserDetail = z.object({\n  age: z.number(),\n  name: z.string(),\n  properties: z.array(Property).max(6).describe(\"Manageable set of properties\"),\n});\n</code></pre>"},{"location":"concepts/tips/#defining-entity-relationships","title":"Defining Entity Relationships","text":"<p>Explicitly define relationships in your schemas, like user friends' IDs.</p> <pre><code>const UserDetail = z.object({\n  id: z.number(),\n  age: z.number(),\n  name: z.string(),\n  friends: z.array(z.number()).describe(\"List of friend IDs, representing user relationships\"),\n});\n</code></pre>"},{"location":"concepts/tips/#reusing-components-in-different-contexts","title":"Reusing Components in Different Contexts","text":"<p>Reuse components in various contexts by defining them separately.</p> <pre><code>const TimeRange = z.object({\n  startTime: z.number().describe(\"Start time in hours.\"),\n  endTime: z.number().describe(\"End time in hours.\"),\n});\n\nconst UserDetail = z.object({\n  id: z.number(),\n  age: z.number(),\n  name: z.string(),\n  workTime: TimeRange,\n  leisureTime: TimeRange,\n});\n</code></pre> <p>These guidelines should streamline and enhance your Zod schema creation and validation processes.</p>"},{"location":"examples/","title":"Cookbook","text":"<p>Page under construction</p> <p>This page is under construction. Please check back later. Consider contributing to this page by opening a PR! Theres a bunch of examples in the python version, including documentation here python docs</p> <p>If you want to contribute, please check out issues</p>"},{"location":"examples/#table-of-contents","title":"Table of Contents","text":"<ul> <li>How do I do classification?</li> <li>How are complex queries decomposed into subqueries for a single request?</li> <li>How are action items and dependencies generated from transcripts?</li> </ul>"},{"location":"examples/action_items/","title":"Example: Extracting Action Items from Meeting Transcripts","text":"<p>In this guide, we'll walk through how to extract action items from meeting transcripts using OpenAI's API. This use case is essential for automating project management tasks, such as task assignment and priority setting.</p> <p>Motivation</p> <p>Significant amount of time is dedicated to meetings, where action items are generated as the actionable outcomes of these discussions. Automating the extraction of action items can save time and guarantee that no critical tasks are overlooked.</p>"},{"location":"examples/action_items/#defining-the-structures","title":"Defining the Structures","text":"<p>We'll model a meeting transcript as a collection of <code>Ticket</code> objects, each representing an action item. Every <code>Ticket</code> can have multiple <code>Subtask</code> objects, representing smaller, manageable pieces of the main task.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst PrioritySchema = z.enum([\"HIGH\", \"MEDIUM\", \"LOW\"]);\n\nconst SubtaskSchema = z.object({\n  id: z.number(),\n  name: z.string(),\n})\n\nconst TicketSchema = z.object({\n  id: z.number(),\n  name: z.string(),\n  description: z.string(),\n  priority: PrioritySchema,\n  assignees: z.array(z.string()),\n  subtasks: z.array(SubtaskSchema).optional(),\n  dependencies: z.array(z.number()).optional()\n})\n\nconst ActionItemsSchema = z.object({\n  items: z.array(TicketSchema)\n})\n\ntype ActionItems = z.infer&lt;typeof ActionItemsSchema&gt;\n</code></pre>"},{"location":"examples/action_items/#extracting-action-items","title":"Extracting Action Items","text":"<p>To extract action items from a meeting transcript, we use the <code>extractActionItems</code> function. It calls OpenAI's API, processes the text, and returns a set of action items modeled as <code>ActionItems</code>.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\",\n})\n\nconst extractActionItems = async (data: string): Promise&lt;ActionItems | undefined&gt; =&gt; {\n  const actionItems: ActionItems = await client.chat.completions.create({\n    messages: [\n      {\n        \"role\": \"system\",\n        \"content\": \"The following is a transcript of a meeting...\",\n      },\n      {\n        \"role\": \"user\",\n        \"content\": `Create the action items for the following transcript: ${data}`,\n      },\n    ],\n    model: \"gpt-4-1106-preview\",\n    response_model: { schema: ActionItemsSchema },\n    max_tokens: 1000,\n    temperature: 0.0,\n    max_retries: 2,\n  })\n\n  return actionItems || undefined\n}\n</code></pre>"},{"location":"examples/action_items/#evaluation-and-testing","title":"Evaluation and Testing","text":"<p>To test the <code>extractActionItems</code> function, we provide it with a sample transcript, and then print the JSON representation of the extracted action items.</p> <pre><code>const actionItems = await extractActionItems(\n`Alice: Hey team, we have several critical tasks we need to tackle for the upcoming release. First, we need to work on improving the authentication system. It's a top priority.\n\nBob: Got it, Alice. I can take the lead on the authentication improvements. Are there any specific areas you want me to focus on?\n\nAlice: Good question, Bob. We need both a front-end revamp and back-end optimization. So basically, two sub-tasks.\n\nCarol: I can help with the front-end part of the authentication system.\n\nBob: Great, Carol. I'll handle the back-end optimization then.\n\nAlice: Perfect. Now, after the authentication system is improved, we have to integrate it with our new billing system. That's a medium priority task.\n\nCarol: Is the new billing system already in place?\n\nAlice: No, it's actually another task. So it's a dependency for the integration task. Bob, can you also handle the billing system?\n\nBob: Sure, but I'll need to complete the back-end optimization of the authentication system first, so it's dependent on that.\n\nAlice: Understood. Lastly, we also need to update our user documentation to reflect all these changes. It's a low-priority task but still important.\n\nCarol: I can take that on once the front-end changes for the authentication system are done. So, it would be dependent on that.\n\nAlice: Sounds like a plan. Let's get these tasks modeled out and get started.`\n)\n\nconsole.log({ actionItems: JSON.stringify(actionItems) })\n</code></pre>"},{"location":"examples/action_items/#visualizing-the-tasks","title":"Visualizing the tasks","text":"<p>In order to quickly visualize the data we used code interpreter to create a graphviz export of the json version of the ActionItems array.</p> <p></p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"name\": \"Improve Authentication System\",\n      \"description\": \"Revamp the front-end and optimize the back-end of the authentication system\",\n      \"priority\": \"High\",\n      \"assignees\": [\"Bob\", \"Carol\"],\n      \"subtasks\": [\n        {\n          \"id\": 2,\n          \"name\": \"Front-end Revamp\"\n        },\n        {\n          \"id\": 3,\n          \"name\": \"Back-end Optimization\"\n        }\n      ],\n      \"dependencies\": []\n    },\n    {\n      \"id\": 4,\n      \"name\": \"Integrate Authentication System with Billing System\",\n      \"description\": \"Integrate the improved authentication system with the new billing system\",\n      \"priority\": \"Medium\",\n      \"assignees\": [\"Bob\"],\n      \"subtasks\": [],\n      \"dependencies\": [1]\n    },\n    {\n      \"id\": 5,\n      \"name\": \"Update User Documentation\",\n      \"description\": \"Update the user documentation to reflect the changes in the authentication system\",\n      \"priority\": \"Low\",\n      \"assignees\": [\"Carol\"],\n      \"subtasks\": [],\n      \"dependencies\": [2]\n    }\n  ]\n}\n</code></pre> <p>In this example, the <code>extractActionItems</code> function successfully identifies and segments the action items, assigning them priorities, assignees, subtasks, and dependencies as discussed in the meeting.</p> <p>By automating this process, you can ensure that important tasks and details are not lost in the sea of meeting minutes, making project management more efficient and effective.</p>"},{"location":"examples/classification/","title":"Text Classification","text":"<p>This tutorial showcases how to implement text classification tasks\u2014specifically, single-label and multi-label classifications\u2014using the OpenAI API.</p> <p>Motivation</p> <p>Text classification is a common problem in many NLP applications, such as spam detection or support ticket categorization. The goal is to provide a systematic way to handle these cases using OpenAI's GPT models.</p>"},{"location":"examples/classification/#single-label-classification","title":"Single-Label Classification","text":""},{"location":"examples/classification/#defining-the-structures","title":"Defining the Structures","text":"<p>For single-label classification, we first define an <code>enum</code> for possible labels and a Pydantic model for the output.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nenum CLASSIFICATION_LABELS {\n  \"SPAM\" = \"SPAM\",\n  \"NOT_SPAM\" = \"NOT_SPAM\"\n}\n\nconst SimpleClassificationSchema = z.object({\n  class_label: z.nativeEnum(CLASSIFICATION_LABELS)\n})\n\ntype SimpleClassification = z.infer&lt;typeof SimpleClassificationSchema&gt;\n</code></pre>"},{"location":"examples/classification/#classifying-text","title":"Classifying Text","text":"<p>The function <code>classify</code> will perform the single-label classification.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\"\n})\n\nasync function classify(data: string): Promise&lt;SimpleClassification&gt; {\n  const classification = await client.chat.completions.create({\n    messages: [{ role: \"user\", content: `\"Classify the following text: ${data}` }],\n    model: \"gpt-3.5-turbo\",\n    response_model: { schema: SimpleClassificationSchema },\n    max_retries: 3\n  })\n\n  return classification\n}\n\nconst classification = await createClassification(\n  \"Hello there I'm a nigerian prince and I want to give you money\"\n)\n\nconsole.log({ classification })\n// { class_label: 'SPAM' }\n</code></pre>"},{"location":"examples/classification/#multi-label-classification","title":"Multi-Label Classification","text":""},{"location":"examples/classification/#defining-the-structures_1","title":"Defining the Structures","text":"<p>For multi-label classification, we introduce a new enum class and a different Pydantic model to handle multiple labels.</p> <pre><code>enum MULTI_CLASSIFICATION_LABELS {\n  \"BILLING\" = \"billing\",\n  \"GENERAL_QUERY\" = \"general_query\",\n  \"HARDWARE\" = \"hardware\"\n}\n\nconst MultiClassificationSchema = z.object({\n  predicted_labels: z.array(z.nativeEnum(MULTI_CLASSIFICATION_LABELS))\n})\n\ntype MultiClassification = z.infer&lt;typeof MultiClassificationSchema&gt;\n</code></pre>"},{"location":"examples/classification/#classifying-text_1","title":"Classifying Text","text":"<p>The function <code>multi_classify</code> is responsible for multi-label classification.</p> <pre><code>async function multi_classify(data: string): Promise&lt;MultiClassification&gt; {\n  const classification = await client.chat.completions.create({\n    messages: [{ role: \"user\", content: `\"Classify the following support ticket: ${data}` }],\n    model: \"gpt-3.5-turbo\",\n    response_model: { schema: MultiClassificationSchema },\n    max_retries: 3\n  })\n  return classification \n}\n\nconst classification = await createClassification(\n  \"My account is locked and I can't access my billing info. Phone is also broken\"\n)\n\nconsole.log({ classification })\n// { predicted_labels: [ 'billing', 'hardware' ] }\n</code></pre>"},{"location":"examples/query_decomposition/","title":"Planning and Executing a Query Plan","text":"<p>This example demonstrates how to use the OpenAI Function Call ChatCompletion model to plan and execute a query plan in a question-answering system. By breaking down a complex question into smaller sub-questions with defined dependencies, the system can systematically gather the necessary information to answer the main question.</p> <p>Motivation</p> <p>The goal of this example is to showcase how query planning can be used to handle complex questions, facilitate iterative information gathering, automate workflows, and optimize processes. By leveraging the OpenAI Function Call model, you can design and execute a structured plan to find answers effectively.</p> <p>Use Cases:</p> <ul> <li>Complex question answering</li> <li>Iterative information gathering</li> <li>Workflow automation</li> <li>Process optimization</li> </ul> <p>With the OpenAI Function Call model, you can customize the planning process and integrate it into your specific application to meet your unique requirements.</p>"},{"location":"examples/query_decomposition/#defining-the-structures","title":"Defining the structures","text":"<p>Let's define the necessary models to represent the query plan and the queries.</p> <pre><code>import Instructor from \"@/instructor\"\nimport OpenAI from \"openai\"\nimport { z } from \"zod\"\n\nconst QueryTypeSchema = z.enum([\"SINGLE\", \"MERGE_MULTIPLE_RESPONSES\"]);\n\nconst QuerySchema = z.object({\n  id: z.number(),\n  question: z.string(),\n  dependencies: z.array(z.number()).optional(),\n  node_type: QueryTypeSchema.default(\"SINGLE\")\n})\n\nconst QueryPlanSchema = z.object({\n  query_graph: z.array(QuerySchema)\n})\n</code></pre> <p>Graph Generation</p> <p>Notice that this example produces a flat list of items with dependencies that resemble a graph, while pydantic allows for recursive definitions, it's much easier and less confusing for the model to generate flat schemas rather than recursive schemas. If you want to see a recursive example, see recursive schemas</p>"},{"location":"examples/query_decomposition/#planning-a-query-plan","title":"Planning a Query Plan","text":"<p>Now, let's demonstrate how to plan and execute a query plan using the defined models and the OpenAI API.</p> <pre><code>const oai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY ?? undefined,\n  organization: process.env.OPENAI_ORG_ID ?? undefined\n})\n\nconst client = Instructor({\n  client: oai,\n  mode: \"FUNCTIONS\",\n})\n\nconst createQueryPlan = async (question: string): Promise&lt;QueryPlan | undefined&gt; =&gt; {\n  const queryPlan: QueryPlan = await client.chat.completions.create({\n    messages: [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a world class query planning algorithm capable of breaking apart questions into its dependency queries such that the answers can be used to inform the parent question. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. Before you call the function, think step-by-step to get a better understanding of the problem.\",\n      },\n      {\n        \"role\": \"user\",\n        \"content\": `Consider: ${question}\\nGenerate the correct query plan.`,\n      },\n    ],\n    model: \"gpt-4-1106-preview\",\n    response_model: { schema: QueryPlanSchema },\n    max_tokens: 1000,\n    temperature: 0.0,\n    max_retries: 2,\n  })\n\n  return queryPlan || undefined\n}\n\nconst queryPlan = await createQueryPlan(\n  \"What is the difference in populations of Canada and the Jason's home country?\"\n)\n\nconsole.log({ queryPlan: JSON.stringify(queryPlan) })\n</code></pre> <p>No RAG</p> <p>While we build the query plan in this example, we do not propose a method to actually answer the question. You can implement your own answer function that perhaps makes a retrival and calls openai for retrival augmented generation. That step would also make use of function calls but goes beyond the scope of this example.</p> <pre><code>{\n  \"query_graph\": [\n    {\n      \"id\": 1,\n      \"question\": \"What is the population of Canada?\",\n      \"dependencies\": [],\n      \"node_type\": \"SINGLE\"\n    },\n    {\n      \"id\": 2,\n      \"question\": \"What is the name of Jason's home country?\",\n      \"dependencies\": [],\n      \"node_type\": \"SINGLE\"\n    },\n    {\n      \"id\": 3,\n      \"question\": \"What is the population of {country}?\",\n      \"dependencies\": [2],\n      \"node_type\": \"SINGLE\"\n    },\n    {\n      \"id\": 4,\n      \"question\": \"What is the difference in population between Canada and {country}?\",\n      \"dependencies\": [1, 3],\n      \"node_type\": \"MERGE_MULTIPLE_RESPONSES\"\n    }\n  ]\n}\n</code></pre> <p>In the above code, we define a <code>createQueryPlan</code> function that takes a question as input and generates a query plan using the OpenAI API.</p>"},{"location":"examples/query_decomposition/#conclusion","title":"Conclusion","text":"<p>In this example, we demonstrated how to use the OpenAI Function Call <code>ChatCompletion</code> model to plan and execute a query plan using a question-answering system. We defined the necessary structures using Pydantic and created a query planner function.</p>"},{"location":"blog/archive/2024/","title":"2024","text":""}]}